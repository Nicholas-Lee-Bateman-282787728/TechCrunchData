As technology giantsaccelerate humanitytowards a driverless car future, where weare conditioned tokeep oureyeballs on ourdeviceswhile algorithmstake the wheel and navigate the vagaries of the open road, safety questions crash headlong into ethical and philosophical considerations.Earlier this year Google blogged about the eleven minor accidents its driverless cars had been involved in over six years of testing  laying the blame for all 11 incidents at the hands of the other human drivers. Which sounds great for the technology on the surface. But in reality it underlinesthe inherent complexitiesof blending two very different styles of driving  and suggests thatrobot cars might actually be too cautious and careful.Combine that cautious, by-the-book approachwith human drivers tendency to take risks and cut corners, and well, that, in itself, might indicatedriverless cars risk aversion isan accident waiting to happen (at least when human drivers are also in the mix).Google is now trying to train its cars to drive abit more humanistically, as a Google driverless car bod put it this summer, using a word that seems better suited to the lexicon of a robot. Which boils down togetting robots to act a bit more aggressively at the wheel. Truly these are strange days.Autonomous vehiclesnavigating open roads guided only byalgorithmic smarts is certainly an impressive technical achievement. But successfully integrating suchdriverlessvehicles into the organic, reactive chaos of (for now) human-motorist dominated roadswill be an even more impressive achievement  andwere not there yet. Frankly the technical progressachieved thus far, by Google and others in this field, may prove the far easier portion of what remains avery complexproblem.The last mile of driverless carsis going torequire an awful lot of engineering sweat,andregulatory and societyaccord about acceptable levels of risk (including very sizable risks to a wholeswathe ofhuman employment). Self-drivingcar-makers accepting blanket liability for accidents is one way the companies involved are trying toaccelerate the market.As youd expect, California has been at the forefront of fueling tech developments here. Its DMV is currently developing regulations for what it dryly dubs the post-testing deployment of autonomous vehicles  a process thats, unsurprisingly given the aforementioned complexities, lagging farbehind schedule, with no draft rules published yet, despite thembeing slated toarriveat the start of this year.The DMVhas just publishedall the official accident reports involving autonomous vehiclestested on Californias roads, covering the period fromlast September to date, on its website.This data mostly pertains to Googles driverless vehicles, with eight of the nine reports involving Mountain View robot cars. The other one is an autonomous vehicle made by Delphi Automatic.The reports appear tosupportGoogles claims that human error bythe drivers of thenon-autonomous cars is, on the surface, causing accidents. However thedifficulties caused by the co-mingling of human and robot driving styles is also inample evidence.In one report, from April this year, a low-speed rear-shunt occurred when arobot carin the midst of attempting to turn right at an intersectionapplied the brakesto avoid an oncoming car, after initiallycreeping forward. The human-driven car behind it,also trying to turn right and presumably encouraged by the Lexus creeping forward, then failed to brake sufficiently and so collided withtherear of the Google Lexus.In another report, from June this year, a Google Lexus traveling in autonomous vehicle mode was also shunted from behind at low speed by a human-driven car. In this instance the robot carwas obeying a red stop sign that was still showing for the lane it was occupying. The human driver behind was apparently spurred on to drive into the back of the stationary Lexusbecause of agreen light appearing  albeit for a left-turn lane (whereas the two cars were actually occupyingthe straight ahead lane).A third report, from this July, details how another Google Lexus wascrashed into from behind by a human driver  this time after decelerating to a stop in traffic because ofstopped traffic ahead ofa green lit traffic intersection. Presumably the human driver was paying moreattention to the green traffic signal than to the changing road conditions.Most of the accidents detailed in the reports occurred at very low speeds. But that might be more a consequence of the type of road-testingdriverless cars are currently engaged in, if the focus of current tests for makers isurban navigation and all its messy complexities. While Googles cars being involvedin the majority of the reports is likely down to the companyclocking up the most driverless mileage, having been committed tothe space for so many years.Back in May Googlesaid its 20+ self-driving cars were averaging around 10,000 self-driven milesper week. The fleet had clocked up almosta million milesover a six year testingperiod at that point, so has likely added a further 200,000 miles or so since then  assuming rates of testing remained the same.All the DMVs Google-related accident reports pertain to this year, with six accident reports coveringthe first half of the year, including two in June and two in April.There are currently 10 companies approved by the DMV to test driverless cars on Californias roads:Volkswagen Group of America, Mercedes Benz, Google, Delphi Automotive, Tesla Motors, Bosch, Nissan, Cruise Automation, BMW and Honda.Apple also apparently recently met with the DMV to discuss the departmentsforthcoming driverless vehicleregulations  adding more fuel to rumors Cupertino is also working on developing a (self-driving?) electric car.