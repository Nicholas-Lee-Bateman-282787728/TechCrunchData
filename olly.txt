A robot with aunique personality might sound like an oxymoron. Or science fiction. But thats the goal of London-based startup Emotech,launching on stage at TechCrunch Disrupt London 2015 today, with a plan to crowdfund its first product, a voice-controlled robot assistant called Olly, early next year.The bot takes the form of ananimated eyeball that is housed in a lamp-shaped cup designed to roll around on your tabletop. So if the thought of a large blinking eyeball that swivels around to look at you when you speak and talks back  makes you feel at all uneasy, well, this may not be the bot for you.Emotech insists the look theyre going for is cute, not creepy.The team includes an ex-Dreamworks animator who has worked on movies includingRise of The Guardians and The Croods.Right now Olly is just a prototype, and the team had some demo troubles with their prototype on stage. But the vision is a smart lifestyle assistant, says co-founder Chelsea Chen  one that will havea unique personality, based on the personality of its particular owner. How you interact with Olly, and whatyour personal interests are, will be used to determinethe tonality of yourbot, she says.Based on the AI and the machine learning, we create a special persuading system which [along with the owner] will give Olly special personality, says Chen. Your Olly will be different tomy Olly. Because your personality is different tomine, and your lifestyle is different.For example Im quite curious about everything, so my Olly is more pro-active, talks fast and any time when I try to communicate with Olly, Olly always try to give me more information, more options to suggest. But if the person who is more serious, is more logical, all the information Olly will give is not like my very emotional [Olly] but that one will be very data driven.Four of us [at Emotech] are super fans of science-fiction movies so in our mind building a robot is the dream  its the thing we really want to do, she adds.Butwhat exactly will Olly do? As with other voice-commanded, in-home connected devices  or indeed app-based voice assistants like Apples Siri  Ollywill be able to perform info look-ups such as telling you what the weather is going to be like or providing your wake-up call inthe morning.It willalso be able to be used as a hub for controlling multiple smart homedevices, so you could ask it to dim your smart lights, say, and put some music on your wireless speakers (or onits own speakers). When it launches, the devices and services it will be able to hook into include Nest, Philips Hue, Fitbit, Pebble, IFTTT, Spotify and various social media services, according to the team.Beyond the basic connectedvoice-command stuff  which you can of course alreadydo with a device like the Amazon Echo, for examplethe idea is that Olly will also bedoing some autopiloting of your domestic lifestyle needs, as it gets to know you better and learnsyour habits.For example, perhaps you always like to listen to a particular type of music when you get home from work. Olly could figure this out and fire up the relevant tunes  before youve had time to say: Hey Olly, play me some smooth jazz.How long it will takethe bot to adapt to your routines will depend on what you like to do and how often,says co-founderHongbin Zhuang. If its a weekly activity, like reading, it might take several weeks to learn your preferences. But for example lets say wake up in the morning or daily workout it can get the data more frequently which means it does not need a lot of time to learn the curve, he adds.The botsflagshipfunctionality is focused on smarter scheduling, so its being designed to help time-poor professionals who might need a little help optimizing their routines. So youcould, for example, tellit ageneral goal of helping youread more books in the month  and then it will set about prompting you at (hopefully) opportune moments when it thinks you might have a window in your busy scheduleto sit down and read.The basic concept is a little bit like Nest, adds Zhuang.Olly can evolve its personality based on its users preferences and patterns.Initially the user will let Olly know what they want to achieve  what kind of lifestyle they want to have. And then based on this, Olly is going to be able to help the user to organize their schedule and also make some proposals  for example what is a better time for reading, or whats a better time for jogging.The underlying OS for Olly is based on Android. The team intends to release an SDK to expand the functions their devicewill be able tooffer  so theyre envisaging anapp store model helping togrow Ollys utility with the help of outside developers.In terms of how the deviceworks, itwilllisten continuallyfor a voice trigger command before sending any voice data to itscloud platform for processing. So the co-foundersclaim it wont be harvesting and data-mining your private conversations  only recording the stuff youre directing at it. (They alsosaythe user will be able to delete any of the data sentby Olly to the cloud via the companion app.)As well as being equipped with sensitive microphones designed to pick out voice commands from the generaldomestic chaos, Olly also has a camera for facial recognition and computer-vision-powered image processing so the bot can figure out who itslooking at and respond accordingly.Facial detection is done locally on the device, but again, facial recognition requires cloud processing. So when Olly detects a face in its vicinity, it takes a photo and uploads that to the cloud to try to figure out who its looking at.(It is also designed to physically turn to face the person speaking to it, much like another social robot in-the-making,Jibo.)Through face and voice recognition, Olly knows who is the direct owner, but Olly cannot tell who is the guest, adds Chen, explaining what will happen when the robot encounters a personit doesnt yet know.She says the process of introducing newpeople to Olly can be controlled by the direct owner and will be like a real friends introduction  so the owner can presumably say, Olly this is my friend Gemma and the bot will record the name and a photo of the persons face for future reference.Eyeing up the marketOlly is still about a year-and-a-half away from arriving on themarket and does not have a first-mover advantage in this space. There are already several social robots at a more advanced stage of development, such as the aforementionedJibo.Or Softbanks Pepper.Not to mentionthe various other voice assistants  whether theyre in app form, like Siri, or also a connected device, like Amazon Echo.So theres plenty of competition lining up to sell the concept of AI-poweredconvenience to consumers.Its also questionable how much consumer desirethere is forthis sort of tech  especially as itsreally only as useful as it iscapable. And, at this nascent stage, its capabilities arent always that useful. So its a bit of a Catch 22 situation. Even Apples Siri, as it isnow, remainsan iOS feature, rather than a killer app.Despite all these challenges the Emotech team is upbeatabout its mission and about mainstream adoption of robot assistants  as well they must be to be spending so much time and effort building Olly. The team expectsa timeframe ofthree to five years before social robots start gainingtraction with the mainstream, pointing to smart home devices as the tipping point to get consumers feeling hassled enough to wanta robot minion to do some of their domestic lifting.Emotechhasraised 500,000 in angel funding sofar from an undisclosed Chinese investor, and willbe setting an initial target of $100,000 to raise from theircrowdfunding campaign nextFebruary, although theyre hoping to pull in closer to $500,000.We see huge potential in the smart home market. There are going to be 25 billion devices connected to the Internet and most of them are home devices, saysZhuang. So we need this kind of smart hub to help people interact with all these kind of devices.In terms of how Olly compares with the most similar rival device at this stage (Jibo), they stressthe market positioning is different  with the latterbeing pitched as a device for the whole family, whereas Olly is intended to be personal;a robot assistantfor anindividual. While othermembers of your household will be able tointeract with your robot, theyll only get general responses  not the tailored-to-you tonality the trueowner will hear.Olly is also being designed to be more portable than rival devices. They envisage people carrying it around the house as theymove from room toroom and into different parts of theirdomestic routine. Soit will have a built-in battery which theysay will be good for someeight hours of operational time (although betweenthree to four hours of active use per charge).Whether people will really want to scoop up and carry a digital eyeball around the house with them, especially giventhey probably already have their smartphone withthem  and perhaps several wearable devices too  remains to be seen. Cost wise, theyre not fixed on a retail price point yetbut Chen suggestsOlly will be in the region of 200 to 300.The original idea for making a personalized robot assistant came to Zhuang when he was completing his human computer interaction course at University College London. Why make a hardware device at all and not just an app? Its about embodiment, he says. The product, lets say a smartphone, is a device. And you wouldnt treat it like a creature, or kind of emotional system.Whether consumers will warm toan adaptable device likeOlly as if it wereahuman, or view itas justanother gadgetfilled with algorithms, isan open-ended question right now one whichdepends onwhether AI can live up to those sci-fi dreams.Judges Q&AQ: Question about the future of the company  is your ambition to move away from hardware and then license the AI out?A: Now were building the hardware we believe the interaction between people and tech when you have your own hardware the voice detection is going to be much more accurate than for example smartphone.This is our first product. Were going to open our platform. And integrate and provide our AI system to other companies.Q: Do you carry Olly around? How do you interact with it?
A: The final one will be smaller and lighter. In general Olly going to live in the main places youre going to interact with it. For example in the living room. In the morning it can wake you up. Were going to build our own voice detection system so the microphone can detect you across the room.When you cooking, you put Olly in the kitchen. When you sleep you put it beside you.Q: How does it differ from Amazon Echo?A: In terms of Echo a lot of similar devices on the market. We are trying to make the interaction between the robot and the user more human like. As you can see it can have different emotions. It has personality based on your personality.