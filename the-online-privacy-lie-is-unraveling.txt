Anew reportinto U.S. consumers attitude to the collection of personal datahas highlighted the disconnect between commercial claimsthat web usersare happy to trade privacy in exchange for benefits like discounts. On the contrary, it asserts thata large majority of web users are not at all happy, but rather feel powerless to stop their data being harvested and used bymarketers.The report authors argue its this sense of resignation that is resulting in data tradeoffs taking place  rather than consumers performing careful cost-benefit analysis to weigh up the pros and cons of giving up their data (as marketers try to claim). They also foundthat where consumers were mostinformedabout marketing practices they were alsomore likely to be resigned to not being able to do anything to prevent their data being harvested.Rather than feeling able tomake choices, Americans believe it is futile to manage what companies can learn about them. Our studyreveals that more than half do not want to lose control over their information but also believe this loss ofcontrol has already happened, the authors write.By misrepresenting the American people and championing the tradeoff argument, marketers givepolicymakers false justifications for allowing the collection and use of all kinds of consumer data oftenin ways that the public find objectionable. Moreover, the futility we found, combined with a broadpublic fear about what companies can do with the data, portends serious difficulties not just forindividuals but also  over time  for the institution of consumer commerce.It is not difficult to predictwidespread social tensions, and concerns about democratic access to the marketplace, if Americanscontinue to be resigned to a lack of control over how, when, and what marketers learn about them, they add.The report, entitled The Tradeoff Fallacy: How marketers are misrepresenting American consumers and opening them up to exploitation,is authored by three academics from the University of Pennsylvania, and is based on arepresentative national cellphone and wireline phone survey of more than 1,500 Americans age 18 and older who use the internet or email atleast occasionally.Key findings on American consumers include that The authors go on to note that only about 4% agree or agree strongly with all three of the above propositions. And even with a broader definition of a belief in tradeoffs they found just a fifth (21%) were comfortably accepting of the idea. So the survey foundvery much a minority of consumers are happy with current data tradeoffs.The report also flags up thatlarge numbers (often a majority) of U.S. consumers are unaware of how theirpurchaseand usage data can be sold on or shared withthird parties without their permission or knowledge  in many instancesfalsely believing they have greater data protection rights than they are in fact afforded by law.Examples the report notes include Data-miningin the spotlightOne thing is clear: the great lie about online privacy is unraveling. The obfuscated commercial collection of vast amounts of personal data in exchange for free services is graduallybeing revealed for what it is: a heist of unprecedented scale. Behind thebland, intellectually dishonest facade that claimstheresnothing to see heregigantic data-mining apparatus have been manoeuvered into place, atop vast mountainsof stolen personal data.Stolen because it has never been made clear to consumers what is being taken, and how that information is being used. How can you consent to something you dont know or understand? Informed consent requires transparency and an ability to control what happens. Both of which aresystematically undermined by companies whose business models require that vast amounts of personal data be shoveled ceaselessly intotheir engines.Thisis why regulators are increasingly focusing attention on the likes ofGoogle and Facebook. And why companies with different business models, such as hardware maker Apple, are joining the chorus of condemnation. Cloud-based technology companies large and smallhave exploited and encouraged consumer ignorance, concealing their data-mining algorithms and processes inside proprietary black boxes labeled commercially confidential. The larger entitiesspend big onpumping out a steady stream of marketing misdirection  distracting their users with shiny new things, or proffering uphollowreassurances about how they dont sell your personal data.Make no mistake: this isequivocation. Googlesells access to itssurveillance intelligence on who usersarevia its ad-targeting apparatus  so itdoesnt need to sellactual data. Itsintelligence on web usershabits and routines and likes and dislikesis far more lucrative than handing over the digits of anyonesphone number. (The company isalso moving in the direction of becoming an online marketplace in itsown right  by adding a buy button directly to mobile search results.So itsintending tocapture, process and convert more transactions itselfdirectly choreographinguserscommercial activity.)These platforms also work to instilla feeling of impotence in users in varioussubtle ways, burying privacy settings within labyrinthine submenus. And technical information in unreadable terms and conditions. Doing everything they can to fog rather than fess up to the reality of the gigantic tradeoff lurking in the background. Yet slowly, but slowlythissophisticatedsurveillance apparatus is being dragged into the light.The privacycosts involved for consumers who pay for free services by consenting toinvasive surveillance of what they say, where they go, who they know, what they like, what they watch, what they buy, have never been made clear by the companies involved in big data mining. But costs are becoming more apparent, as glimpses of the extent of commercialtracking activities leak out.And as more questions are asked the discrepancy between the claim that theresnothing to see here vsthe reality of sleepless surveillance apparatus peering over yourshoulder, logging yourpulse rate, reading yourmessages, noting what you look at, for how long and what you do next  and doing sotooptimize the lifting ofmoney out of your wallet  then the true consumer cost of free becomes more visiblethan it has ever been.The tradeoff lie is unraveling, as the scale andimplications of the data heist are starting to be processed. One clear tipping point here isNSA whistleblowerEdward Snowden who, two years ago, risked life andliberty to reveal how the U.S. government (and many other governments) were involved in a massive, illegal loggingof citizens digital communications. The documents he released also showedhow commercial technology platforms had been appropriated and drawn into this secretive state surveillance complex. Once governments were implicated, it was only a matter of time before the big Internet platforms,with theirmirror data-capturingapparatus, would facequestions.Snowdens revelations have had various reforming political implications for surveillance in the U.S. andEurope. Tech companies have also been forced to takepublic stances  either to loudly defend user privacy, or be implicated by silence and inaction.Another catalyst for increasing privacy concerns is the Internet of Things. A physical network of connected objects blinking and pinging notifications is itself a partial reveal of the extent of the digital surveillance apparatus that has beendeveloped behind commercially closed doors.Modern consumer electronics are hermetically sealedblack boxes engineered to conceal complexity. But the complexities of hooking all these smart sensornet objects together, and placingso many data-sucking tentacles on display, in increasingly personal places(the home, the body) starts to makesurveillance infrastructureand its implications uncomfortablyvisible.Plus this time its manifestlypersonal. Its in your home and on your person  whichadds to agrowing feeling of beingcreeped out and spied upon. Andas more and morestudieshighlight consumer concern about how personal data is being harvested and processed, regulators are also taking notice and turningup the heat.One response to growing consumer concerns about personal data came this week with Google launching a centralized dashboard for users to access (some) privacy settings. Its far from perfect, and contains plentiful misdirection aboutthecompanysmotives,but its telling that this ad-fueled behemothfeels the need to be more pro-active inits presentation of its attitude and approach to userprivacy.Radical transparencyThe Tradeoff report authors include a section at the end withsuggestions for improving transparency around marketing processes, calling forinitiatives that will give members of the public the right and abilityto learn what companies know about them, how they profile them, and what data lead to whatpersonalized offers  and forgetting consumers excited about using that right and ability.Among their suggestions to boost transparency and corporate openness are As long as the algorithms companies implement toanalyze and predict the future behaviors of individuals are hidden from public view, the potentialfor unwanted marketer exploitation of individuals data remains high. We therefore ought toconsider it an individuals right to access the profiles and scores companies use to create everypersonalized message and discount the individual receives, the report adds.Companies will push back thatgiving out this information will expose trade secrets. We argue there are ways to carry this outwhile keeping their trade secrets intact.Theyre not the only ones calling for algorithms to be pulled into view either  back in April theFrench Senate backed calls for Google to reveal the workings of itssearch ranking algorithms. In that instance the focusis commercial competition toensure a level playing field, rather than user privacy per se, but its clear that more questions are being asked about the power of proprietary algorithms and the hidden hierarchies they create.Startups should absolutely see the debunking of the myth that consumers are happy to trade privacy for free servicesas a fresh opportunityfor disruption  to build services that stand out because they arent predicatedonthe assumption that consumers can and shouldbe tricked into handing over data and having their privacy undermined on the sly.Servicesthatstandupona futureproofedfoundationwhere operational transparency inculcates user trustsetting these businessesup for bona fidedata exchanges, rather than shadowytradeoffs.