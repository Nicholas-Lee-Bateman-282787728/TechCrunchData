What if the apps on your phone knew where you were, what you were doing, whats nearby, and even what the weather was like outside, and then combined this information to react intelligently to your current situation?Would that be creepy or amazing? We will soon find out, it seems. At this weeks Google I/O conference, the company introducednew tools for app developers that will allow them to create applications that customize themselves to a userscurrent context.For example, a streaming music application could display an energetic playlist when you plug in your headphones and start jogging.Or perhaps an app could alert you to stop by the pharmacy to pick up your medications  but it would only do so ifyou were driving, near the store, and the store was actually open.To make these sorts of smarter applications possible, Google is introducing a new Awareness API which will become available shortly after its I/O conference wraps.Effectively, this API combines a variety of functions previously available via other APIs  like gaining access to a users location or recognizing that theyre now driving their vehicle, for example. It can even sense nearby beacons and devices, which means it can tap into data from things like Android Wear smartwatches, or interoperate with devices like Chromecast (Google Cast) or Googles new smart speaker, Google Home.Google suggested a number of use cases, besides the examples above, as tohow this functionality could be implemented in future applications.For instance, a smarter alarm clock app could decide when to wake you up based on how late you stayed up the night before, and when your first meeting is that day.A weather application could sense the Chromecast plugged intoyour bedroom TV and project the days weather onto the screen.An assistant application could wake up Google Home to tell you that its time to leave for your calendar appointment.A running app could immediately logyour run for you, even if you forgot to start the tracking function.A launcher application could place your camera app front-and-center when youre outside because it knows you take a lot of nature photos outdoors. And, as an added bonus, when you snap the photo, it tags it with the weather and activity. This becomes part of the photos metadata, allowing you tolater search for outdoor photos taken while running and it was sunny outside.Some of these functionswere possible before, if developers usedmultiple APIs. However,Google explained that calling upon multiple APIs, depending on conditions, candrain the battery or make the device run sluggishly due to increased RAM usage.That could lead to users getting frustrated with the app and possibly even uninstalling it from their phone.The new Awareness API, then, not only offers the convenience of requesting all this information about a users situation more easily, it also does so while optimizing for system health. That means the apps get smarter without slowing the phone down or killing your battery.The Awareness API actually contains two distinct APIs  one that lets apps react to the current situation (Fence API) and another to request information about the users current context (Snapshot API).While Googles suggested examples sound interesting, some of the real-world use cases implemented by partners who had early access to the API are a bit less inspiring.Real estate app Trulia, for instance, is using the API for smarter push notifications. That is, it will alert you to visit an open house only if youre nearby, walking, and its nice outside.Runkeeper will let you tag your running posts with the current weather.GrubHub and Aviary are also tapping into the weather to personalize their apps.Latin American music streaming app Superplayer Music, however, seems a littlemore fun. It willsuggest music based on where you are and what youre doing. If you just got to the gym, it will suggest different music than if youre about to start a road trip, for example.And Android launcher Nova is considering rewriting its app to be context aware  meaning it will show you the right apps at the right time.Creating a contextually aware mobile experience is something other startups have attempted before, often in the form of a launcher, like Aviates launcher that Yahoo acquired in 2014. But people haveso far resisted having their phones user interface overhauled in reaction to their surroundings.Thats why it makes sense for this situational awareness to become more deeply embedded in the apps themselves. Instead of asking users to readjust how they use their phone, the experience of using the phone just gets better as notifications get smarter and less bothersome, apps react to what youre doing, and interoperate with other devices around you more seamlessly.Developers can sign up for early access here.