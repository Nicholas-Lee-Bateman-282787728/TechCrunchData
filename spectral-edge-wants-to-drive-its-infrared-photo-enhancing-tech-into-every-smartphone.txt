Smartphone cameras areso goodthese daysit can seemalmost churlish to yearn for improvements. And yetenhancements continue to shave away at imperfections as engineers turn the screw to optimize multipleaspects of image capture hardware and software.To wit: U.K. based startup Spectral Edge has developed a mathematical technique for improving photographic imagery, blending data captured by a standard cameralens with an infrared shot of the same scene in order toenhance the depth and color of the photo.Itscomputation photography technique, called Phusion, works especially well for sharpening detail in shots taken on hazy days or when elements in the scene have been over-exposed, according to MDChristopher Cytera.Its bringing extra detail into the picture that you cant necessarily see with a normal camera. Because infrared penetrates through mist and fog much better than visible light. And so when you have a picture with a little bit of mist, little bit of fog you get a much more stunning effect, he tells TechCrunch.The secret sauce is being able to combine the infrared with the visible lightpicture in a way thats pleasing, he adds. Theres been other techniques to combine the two in the past but they dont end up with pictures that are nice to look at.For example, weapons systems used by the military to identify targets have already been using infrared to enhance visibility. But in that case the resulting imagery isenhanced only in autilitarian sense  i.e. to help identify targets. Phusion is designed to serve up better natural looking pictures.You can see some before and after examples on its website.The hard maths underlying the technique involves mappingtherate of change across the entiresceneusingdifferentiation calculations, says Cytera.In simple terms we do it by transforming the pictures into whats called the gradient space. What were doing is were differentiating every pixel with respect to every other pixel and color in multiple dimensions. And what that does is it preserves every single gradientall the gradients and edges in the picture are perfectly preserved.Whereas other techniques try to blend pictures and you end up with blurred effects as a result  you lose edge definition. We dont do that because we differentiate all these pixels.The technique can alsohave the side-effect of airbrushing/beautifyingphotos of people, becausethe infrared filter is able to reduce the appearance of blemishes on human skin. So not only sharper landscapes but slicker selfies too  or at least thats the promise.The techniquecan also apparently enhance low light imagery  a perennial holy grail of smartphone makers, given the inevitable light capture constraints on small sensors.Spectral Edge, which holds patents on the tech, was founded atthe University of East Angliain early 2011, before beingspun out in March 2014. Its announcinga new tranche of funding today  1.5 million, following its $300,000 seedback in 2014  with the aim of commercializing the tech. Investors in the latest round areIQ Capital and Parkwalk Advisors, along with angels from Cambridge Angels and the Cambridge Capital Group.Spectral Edges business model isto license its IP to device makers. So thefunding will be useddevelop the IP product so its ready for licensing, along with further development and testing work of the core tech.Cytera reckons the first commercial deployments could arrive within 18 to 24 months, likely inonhigh end professional cameras initially but trickling down thereafter to smartphone hardware as the required sensors become cheaper to produce in volumes.Heconfirms the startupis talking to some smartphone makers nowbut wont name any names at this stage.An infrared sensor would be needed on a mobile device for the technique to function but Cytera notes that some smartphones already have the necessary hardware such as Googles Tango device, which uses an infrared sensor for gestures. Futuremobile phone camera sensors could alsoincorporate infrared into their sensor mix so that a device with a single lens could grab the necessary image data, without a handset needing to have two camera lens, he adds.In the long run we think this could be in every single phone with no real cost penalty except a bit of software, he says. Maybe [in] five years. Which is what happened with HDR.Although, at this stage, theres plenty more work to do to pave the way for infrared enhanced shots as standard, with Cytera notingthetechdoes not yetfunction in real-time on a mobile device but is rather being post-processed on a laptop. So theyre not there yet.Anearlier route to market than even pro cameras couldbe security cameras, inCyteras view. He notes the technique works in enhancing video too so could be used to improve detail on CCTV videos for security purposes.