Its International Data Privacy Day, not that most people would likely know that  or,some would argue,care. And therein lies the rub. Privacy, we are constantly told by those with their handson the levers of power, is not something usersare botheredabout.Thing is,thats an exceptionally convenient argument  given how much money there is to be made from amassingvast troves of user data. So I just dont buy it. Not whilst so many tech companiespurpled handsstillreek and smokeon the security and privacy front.Perhaps the truthis not so much that people dont care about privacy,butthey are being socially engineered not to care by those with a vested interest in getting their handson the data. Just think of the lengthy T&Cs and EULAs that digitalconsumershave been encouraged to ignore for years. And whichstill routinely gounread almost every time a persondownloads an app or signs up to a digital service.Suspending privacy concerns hasbecome the tacit payment exacted from consumers foraccessing afree service. Which of course means the service is not actually free. But that doesnt mean people dont care about privacy, more that they are being encouraged to trade it to think of privacy as a currency which buys them digital access. To engage ina transaction.The widerproblem thenis thatconsumersare also being socially engineerednot to scrutinize the exact cost of each of these transactions, given it is almost never made plain to them. (Not to mention thatthe cost is not fixed  itcanshift with every service update.) Consumersare encouraged notto ask whether they are getting value for money for trading away theirprivacy. Norquestion how much datathey arereallyhanding over, and whether they are comfortable with that particular trade.So giving up their own privacy also, ironically, requires thatconsumers do not topry too deeply into the motivationsof the entity asking for thatdata. To accept the transactionon trust.This privacy for blind access trade isa one way street. And, in many cases, a very bad deal.To illustrate both the transactional nature of privacy and how leftin the darkconsumers can beaboutthe exact app permissions they are agreeing to when they tap I agree, the makers of encrypted communications software and hardware, Silent Circle andBlackphone,have put together the below video  which attempts to shed light on how extensive and unacceptable some app permissions can be.And in comments madetoday regarding the recent Sony hacks, Silent Circle co-founder Phil Zimmerman  who is also the creator of PGP  urged businessesto start to recognize there isdistinction between locking down corporate security and safeguarding individual privacy. And that respect for the latter can help secure the former.Zimmerman said:Many kinds ofinformation dont need to be stored for long, or at all. If onlyparticipants keep a copy of their correspondence the company cantlose it. Imagine how much worse the damage of a security breach wouldbe if companies routinely kept years of recordings of all employeesphone calls.Protecting the privacy of individuals is why I started PGP, and whyMike and I started Silent Circle. But at Silent Circle weve come torealize that protecting individuals at work may be the strongest formof corporate security possible.In the wake of massive corporate data breaches such asthe Sony hack, and continueddiscoveries of major security holes in digital infrastructure, such as last years Heartbleed  and of course withthe ongoing drip-feed of Snowden revelations, illuminating the vast scale ofgovernment dragnet digital surveillance programs  there is a gathering momentum to tightendigital security(and that means there is, yes,freshopportunities forstartups).And as more pro-privacy businessesand organizations work to illuminate the risks and repercussions of all these apparently incremental privacy trade-offs, expect consumers to start to appreciate where the value really lies.And to transact accordingly.