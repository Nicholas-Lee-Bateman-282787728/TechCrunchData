Using your hand to grasp a pen thats lying on your desk doesnt exactly feel like a chore, but for robots, thats still a really hard thing to do. So to teach robots how to better grasp random objects, Googles research team dedicated 14 robots to the task.The standard way to solve this problem would be for the robot to survey the environment, create a plan for how to grasp the object,then execute on it.In the real world, though, lots of things can change between formulating that plan and executing on it.Google is now using these robots to train a deep convolutional neural network (a technique thats all the rage in machine learning right now) to help its robots predictthe outcome of their grasps based on the camera input and motor commands. Its basically hand-eye coordination for robots.The team says that it took about 3,000 hours of practice (and 800,000 grasp attempts) before it saw the beginnings of intelligent reactive behaviors.The robot observes its own gripper and corrects its motions in real time. It also exhibits interesting pre-grasp behaviors, like isolating a single object from a group, the team writes. All of these behaviors emerged naturally from learning, rather than being programmed into the system.Googles researchers say the average failure rate without training was 34 percent on the first 30 picking attempts. After training, that number was down to 18 percent. Still not perfect, but the next time a robot comes running after you and tries to grab you, remember that it now has an 80 percent chance of succeeding.